{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sq2Sq_train_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqDb0c5bnGFY",
        "outputId": "59432939-d647-4f4d-cb4c-ce17ae0f3a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 44.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 61.4 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=4b6c9897a9cbcc43722d86055070f7182e1862ada0a28a29f2bcb0a8484c32ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.16\n",
            "--2022-05-15 04:01:15--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.147.128, 142.250.125.128, 142.250.136.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.147.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   211MB/s    in 11s     \n",
            "\n",
            "2022-05-15 04:01:26 (178 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "\n",
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "\n",
        "!tar -xf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import pathlib\n",
        "\n",
        "DATAPATH = \"./dakshina_dataset_v1.0\"\n",
        "\n",
        "trainpath = os.path.join(DATAPATH, \"hi\", \"lexicons\", \"hi\"+\".translit.sampled.train.tsv\")\n",
        "valpath = os.path.join(DATAPATH, \"hi\", \"lexicons\", \"hi\"+\".translit.sampled.dev.tsv\")\n",
        "testpath = os.path.join(DATAPATH, \"hi\", \"lexicons\", \"hi\"+\".translit.sampled.test.tsv\")\n",
        "train = pd.read_csv(\n",
        "    trainpath,\n",
        "    sep=\"\\t\",\n",
        "    names=[\"tgt\", \"src\", \"count\"],\n",
        ")\n",
        "val = pd.read_csv(\n",
        "    valpath,\n",
        "    sep=\"\\t\",\n",
        "    names=[\"tgt\", \"src\", \"count\"],\n",
        ")\n",
        "test = pd.read_csv(\n",
        "    testpath,\n",
        "    sep=\"\\t\",\n",
        "    names=[\"tgt\", \"src\", \"count\"],\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# create train data\n",
        "#train_data = preprocess(list(train[\"src\"]), list(train[\"tgt\"]))"
      ],
      "metadata": {
        "id": "D-pfjLd_nHAW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source=list(train[\"src\"])\n",
        "target=list(train[\"tgt\"])\n",
        "\n",
        "source_chars = set()\n",
        "target_chars = set()\n",
        "\n",
        "#removing non str nan types\n",
        "source = [str(x) for x in source]\n",
        "target = [str(x) for x in target]\n",
        "\n",
        "source_words = []\n",
        "target_words = []\n",
        "\n",
        "for src, tgt in zip(source, target):\n",
        "    tgt = \"\\t\" + tgt + \"\\n\"\n",
        "    source_words.append(src)\n",
        "    target_words.append(tgt)\n",
        "    for char in src:\n",
        "        if char not in source_chars:\n",
        "            source_chars.add(char)\n",
        "    for char in tgt:\n",
        "        if char not in target_chars:\n",
        "            target_chars.add(char)\n",
        "\n",
        "source_chars = sorted(list(source_chars))\n",
        "target_chars = sorted(list(target_chars))\n",
        "\n",
        "#The space needs to be appended so that the encode function doesn't throw errors\n",
        "source_chars.append(\" \")\n",
        "target_chars.append(\" \")\n",
        "\n",
        "num_encoder_tokens = len(source_chars)\n",
        "num_decoder_tokens = len(target_chars)\n",
        "max_source_length = max([len(txt) for txt in source_words])\n",
        "max_target_length = max([len(txt) for txt in target_words])\n",
        "\n",
        "print(\"Number of samples:\", len(source))\n",
        "print(\"Source Vocab length:\", num_encoder_tokens)\n",
        "print(\"Target Vocab length:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_source_length)\n",
        "print(\"Max sequence length for outputs:\", max_target_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jidGuclVn-WC",
        "outputId": "06318e17-fd5e-4bcd-fb03-d3a26e0c6f41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 44204\n",
            "Source Vocab length: 27\n",
            "Target Vocab length: 66\n",
            "Max sequence length for inputs: 20\n",
            "Max sequence length for outputs: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dictionary_lookup( vocab):\n",
        "  char2int = dict([(char, i) for i, char in enumerate(vocab)])\n",
        "  int2char = dict((i, char) for char, i in char2int.items())\n",
        "  return char2int, int2char\n"
      ],
      "metadata": {
        "id": "wmI7Csy3r-Nx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(source, target, source_chars, target_chars, source_char2int=None, target_char2int=None):\n",
        "        num_encoder_tokens = len(source_chars)\n",
        "        num_decoder_tokens = len(target_chars)\n",
        "        max_source_length = max([len(txt) for txt in source])\n",
        "        max_target_length = max([len(txt) for txt in target])\n",
        "\n",
        "        source_vocab, target_vocab = None, None\n",
        "        if source_char2int == None and target_char2int == None:\n",
        "            print(\"Generating the dictionary lookups for character to integer mapping and back\")\n",
        "            source_char2int, source_int2char = dictionary_lookup(source_chars)\n",
        "            target_char2int, target_int2char = dictionary_lookup(target_chars)\n",
        "\n",
        "            source_vocab = (source_char2int, source_int2char)\n",
        "            target_vocab = (target_char2int, target_int2char)\n",
        "\n",
        "        encoder_input_data = np.zeros(\n",
        "            (len(source), max_source_length, num_encoder_tokens), dtype=\"float32\"\n",
        "        )\n",
        "        decoder_input_data = np.zeros(\n",
        "            (len(source), max_target_length, num_decoder_tokens), dtype=\"float32\"\n",
        "        )\n",
        "        decoder_target_data = np.zeros(\n",
        "            (len(source), max_target_length, num_decoder_tokens), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        for i, (input_text, target_text) in enumerate(zip(source, target)):\n",
        "            for t, char in enumerate(input_text):\n",
        "                encoder_input_data[i, t, source_char2int[char]] = 1.0\n",
        "            encoder_input_data[i, t + 1 :, source_char2int[\" \"]] = 1.0\n",
        "            for t, char in enumerate(target_text):\n",
        "                # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "                decoder_input_data[i, t, target_char2int[char]] = 1.0\n",
        "                if t > 0:\n",
        "                    # decoder_target_data will be ahead by one timestep\n",
        "                    # and will not include the start character.\n",
        "                    decoder_target_data[i, t - 1, target_char2int[char]] = 1.0\n",
        "            decoder_input_data[i, t + 1 :, target_char2int[\" \"]] = 1.0\n",
        "            decoder_target_data[i, t:, target_char2int[\" \"]] = 1.0\n",
        "        if source_vocab != None and target_vocab != None:\n",
        "            return (\n",
        "                encoder_input_data,\n",
        "                decoder_input_data,\n",
        "                decoder_target_data,\n",
        "                source_vocab,\n",
        "                target_vocab,\n",
        "            )\n",
        "        else:\n",
        "            return encoder_input_data, decoder_input_data, decoder_target_data"
      ],
      "metadata": {
        "id": "2ARqKzI4nr4b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=encode(source_words, target_words, source_chars, target_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3udhx6qs1E9",
        "outputId": "22d09a64-f5e4-4cee-dfad-6edfcc669f25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating the dictionary lookups for character to integer mapping and back\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # create train data\n",
        "(train_encoder_input,\n",
        "    train_decoder_input,\n",
        "    train_decoder_target,\n",
        "    source_vocab,\n",
        "    target_vocab,\n",
        ") = train_data\n",
        "source_char2int, source_int2char = source_vocab\n",
        "target_char2int, target_int2char = target_vocab\n"
      ],
      "metadata": {
        "id": "Jzjik-8fro25"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # create val data (only encode function suffices as the dictionary lookup should be kep the same.\n",
        "val_data = encode(\n",
        "    val[\"src\"].to_list(),\n",
        "    val[\"tgt\"].to_list(),\n",
        "    list(source_char2int.keys()),\n",
        "    list(target_char2int.keys()),\n",
        "    source_char2int=source_char2int,\n",
        "    target_char2int=target_char2int,\n",
        ")\n",
        "val_encoder_input, val_decoder_input, val_decoder_target = val_data\n",
        "source_char2int, source_int2char = source_vocab\n",
        "target_char2int, target_int2char = target_vocab\n",
        "\n",
        "# create test data\n",
        "test_data = encode(\n",
        "    test[\"src\"].to_list(),\n",
        "    test[\"tgt\"].to_list(),\n",
        "    list(source_char2int.keys()),\n",
        "    list(target_char2int.keys()),\n",
        "    source_char2int=source_char2int,\n",
        "    target_char2int=target_char2int,\n",
        ")\n",
        "test_encoder_input, test_decoder_input, test_decoder_target = test_data\n",
        "source_char2int, source_int2char = source_vocab\n",
        "target_char2int, target_int2char = target_vocab\n"
      ],
      "metadata": {
        "id": "HKofhjMFtOyP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#call attention using:\n",
        "from tensorflow.keras.layers import AdditiveAttention"
      ],
      "metadata": {
        "id": "ThB6W4a-1IEa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        " \n",
        "\n",
        "#from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten, Activation, LSTM, SimpleRNN, GRU, TimeDistributed,Concatenate\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model, Sequential,  Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "class Sq2Sq_attention():\n",
        "\n",
        "    def __init__(self, numEncoders,cell_type,latentDim,dropout,numDecoders,hidden,srcChar2Int, tgtChar2Int):\n",
        "        \n",
        "        self.numEncoders = numEncoders\n",
        "        self.cell_type = cell_type\n",
        "        self.latentDim = latentDim\n",
        "        self.dropout =dropout\n",
        "        self.numDecoders = numDecoders\n",
        "        self.hidden = hidden\n",
        "        self.tgtChar2Int = tgtChar2Int\n",
        "        self.srcChar2Int = srcChar2Int\n",
        "    \n",
        "    def build_configurable_model(self):       \n",
        "        if self.cell_type == \"RNN\":\n",
        "            # encoder\n",
        "            encoder_inputs = Input(shape=(None, len(self.srcChar2Int)))\n",
        "            encoder_outputs = encoder_inputs\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = SimpleRNN(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_outputs, state = encoder(encoder_inputs)\n",
        "            encoder_states = [state]\n",
        "\n",
        "            # decoder\n",
        "            decoder_inputs = Input(shape=(None, len(self.tgtChar2Int)))\n",
        "            decoder_outputs = decoder_inputs\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = SimpleRNN(\n",
        "                    self.latentDim,\n",
        "                    return_sequences=True,\n",
        "                    return_state=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                decoder_outputs, _ = decoder(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_outputs = hidden(decoder_outputs)\n",
        "            decoder_dense = Dense(len(self.tgtChar2Int), activation=\"softmax\")\n",
        "            decoder_outputs = decoder_dense(hidden_outputs)\n",
        "            model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "            \n",
        "            return model\n",
        "        \n",
        "        elif self.cell_type == \"LSTM\":\n",
        "            # encoder\n",
        "            encoder_inputs = Input(shape=(None, len(self.srcChar2Int)))\n",
        "            encoder_outputs = encoder_inputs\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = LSTM(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_outputs, state_h, state_c = encoder(encoder_outputs)\n",
        "            encoder_states = [state_h, state_c]\n",
        "\n",
        "            # decoder\n",
        "            decoder_inputs = Input(shape=(None, len(self.tgtChar2Int)))\n",
        "            decoder_outputs = decoder_inputs\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = LSTM(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                decoder_outputs, _, _ = decoder(\n",
        "                    decoder_outputs, initial_state=encoder_states\n",
        "                )\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_outputs = hidden(decoder_outputs)\n",
        "            decoder_dense = Dense(len(self.tgtChar2Int), activation=\"softmax\")\n",
        "            decoder_outputs = decoder_dense(hidden_outputs)\n",
        "            model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "            \n",
        "            return model\n",
        "        \n",
        "        elif self.cell_type == \"GRU\":\n",
        "            # encoder\n",
        "            encoder_inputs = Input(shape=(None, len(self.srcChar2Int)))\n",
        "            encoder_outputs = encoder_inputs\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = GRU(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_outputs, state = encoder(encoder_inputs)\n",
        "            encoder_states = [state]\n",
        "\n",
        "            # decoder\n",
        "            decoder_inputs = Input(shape=(None, len(self.tgtChar2Int)))\n",
        "            decoder_outputs = decoder_inputs\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = GRU(\n",
        "                    self.latentDim,\n",
        "                    return_sequences=True,\n",
        "                    return_state=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                decoder_outputs, _ = decoder(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_outputs = hidden(decoder_outputs)\n",
        "            decoder_dense = Dense(len(self.tgtChar2Int), activation=\"softmax\")\n",
        "            decoder_outputs = decoder_dense(hidden_outputs)\n",
        "            model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "            \n",
        "            return model\n",
        "    \n",
        "    def build_attention_model(self):       \n",
        "        \n",
        "        if self.cell_type == \"RNN\":\n",
        "            # encoder\n",
        "            encoder_inputs = Input(shape=(None, len(self.srcChar2Int)))\n",
        "            encoder_outputs = encoder_inputs\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = SimpleRNN(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_outputs, state = encoder(encoder_inputs) \n",
        "                \n",
        "                if i == 1:\n",
        "                    encoder_first_outputs= encoder_outputs                  \n",
        "            encoder_states = [state]\n",
        "            \n",
        "\n",
        "            # decoder\n",
        "            decoder_inputs = Input(shape=(None, len(self.tgtChar2Int)))\n",
        "            decoder_outputs = decoder_inputs\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = SimpleRNN(\n",
        "                    self.latentDim,\n",
        "                    return_sequences=True,\n",
        "                    return_state=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                decoder_outputs, _ = decoder(decoder_inputs, initial_state=encoder_states)\n",
        "                \n",
        "                if i == self.numDecoders:\n",
        "                    decoder_first_outputs = decoder_outputs\n",
        "\n",
        "            #attention_layer = AttentionLayer(name='attention_layer')\n",
        "            #attention_out, attention_states = attention_layer([encoder_first_outputs, decoder_first_outputs])\n",
        "            attention_out = AdditiveAttention(use_scale=True)([decoder_first_outputs, encoder_first_outputs])\n",
        "\n",
        "\n",
        "            decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_out])\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_time = TimeDistributed(hidden, name='time_distributed_layer')\n",
        "            hidden_outputs = hidden(decoder_concat_input)\n",
        "            decoder_dense = Dense(len(self.tgtChar2Int), activation=\"softmax\")\n",
        "            decoder_outputs = decoder_dense(hidden_outputs)\n",
        "            model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "            \n",
        "            return model\n",
        "        \n",
        "        elif self.cell_type == \"LSTM\":\n",
        "            # encoder\n",
        "            encoder_inputs = Input(shape=(None, len(self.srcChar2Int)))\n",
        "            encoder_outputs = encoder_inputs\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = LSTM(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_outputs, state_h, state_c = encoder(encoder_outputs)\n",
        "                if i == 1:\n",
        "                    encoder_first_outputs= encoder_outputs                  \n",
        "         \n",
        "            encoder_states = [state_h, state_c]\n",
        "\n",
        "            # decoder\n",
        "            decoder_inputs = Input(shape=(None, len(self.tgtChar2Int)))\n",
        "            decoder_outputs = decoder_inputs\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = LSTM(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                decoder_outputs, _, _ = decoder(\n",
        "                    decoder_outputs, initial_state=encoder_states\n",
        "                )\n",
        "                if i == self.numDecoders:\n",
        "                    decoder_first_outputs = decoder_outputs\n",
        "\n",
        "#            attention_layer = AttentionLayer(name='attention_layer')\n",
        "#            attention_out, attention_states = attention_layer([encoder_first_outputs, decoder_first_outputs])\n",
        "\n",
        "            attention_out = AdditiveAttention(use_scale=True)([decoder_first_outputs, encoder_first_outputs])\n",
        "\n",
        "            decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_out])\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_time = TimeDistributed(hidden, name='time_distributed_layer')\n",
        "            hidden_outputs = hidden(decoder_concat_input)\n",
        "            decoder_dense = Dense(len(self.tgtChar2Int), activation=\"softmax\")\n",
        "            decoder_outputs = decoder_dense(hidden_outputs)\n",
        "            model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "            \n",
        "            return model\n",
        "        \n",
        "        elif self.cell_type == \"GRU\":\n",
        "            # encoder\n",
        "            encoder_inputs = Input(shape=(None, len(self.srcChar2Int)))\n",
        "            encoder_outputs = encoder_inputs\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = GRU(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_outputs, state = encoder(encoder_inputs)\n",
        "\n",
        "                if i == 1:\n",
        "                    encoder_first_outputs= encoder_outputs                  \n",
        "         \n",
        "            encoder_states = [state]\n",
        "\n",
        "            # decoder\n",
        "            decoder_inputs = Input(shape=(None, len(self.tgtChar2Int)))\n",
        "            decoder_outputs = decoder_inputs\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = GRU(\n",
        "                    self.latentDim,\n",
        "                    return_sequences=True,\n",
        "                    return_state=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                decoder_outputs, _ = decoder(decoder_inputs, initial_state=encoder_states)\n",
        "                if i == self.numDecoders:\n",
        "                    decoder_first_outputs = decoder_outputs\n",
        "\n",
        "\n",
        "\n",
        "            #attention_layer = AttentionLayer(name='attention_layer')\n",
        "            #attention_out, attention_states = attention_layer([encoder_first_outputs, decoder_first_outputs])\n",
        "            attention_out = AdditiveAttention(use_scale=True)([decoder_first_outputs, encoder_first_outputs])\n",
        "\n",
        "            decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_out])\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_time = TimeDistributed(hidden, name='time_distributed_layer')\n",
        "            hidden_outputs = hidden(decoder_concat_input)\n",
        "            decoder_dense = Dense(len(self.tgtChar2Int), activation=\"softmax\")\n",
        "            decoder_outputs = decoder_dense(hidden_outputs)\n",
        "            model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "            \n",
        "            return model"
      ],
      "metadata": {
        "id": "tx2viffdt77o"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -rf ./TrainedModels /content/gdrive/MyDrive/CS6910/Assignment3/"
      ],
      "metadata": {
        "id": "58ntizxYuJPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wandb.keras import WandbCallback\n",
        "wandb.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "LaCEgAMbpByy",
        "outputId": "83a54464-6cb7-4472-98d9-f1122247291b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220515_040147-2htc4hsg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/muk465/uncategorized/runs/2htc4hsg\" target=\"_blank\">stoic-smoke-5</a></strong> to <a href=\"https://wandb.ai/muk465/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/muk465/uncategorized/runs/2htc4hsg?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f154708cd10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "\n",
        "  config= {\n",
        "      \"cell_type\": \"LSTM\",\n",
        "      \"latentDim\": 256,\n",
        "      \"hidden\": 128,\n",
        "      \"optimiser\": \"adam\",\n",
        "      \"numEncoders\": 1,\n",
        "      \"numDecoders\": 1,\n",
        "      \"dropout\": 0.2,\n",
        "      \"epochs\": 20,\n",
        "      \"batch_size\": 32,\n",
        "  }\n",
        "\n",
        "\n",
        "  #wandb.init(config=config_defaults,  project=\"CS6910-Assignment-3_att\")\n",
        "  #config = wandb.config\n",
        "  '''wandb.run.name = (\n",
        "      str(config.cell_type)\n",
        "      + \"eng\"\n",
        "      + str(config.numEncoders)\n",
        "      + \"_\"\n",
        "      + \"hi\"\n",
        "      + \"_\"\n",
        "      + str(config.numDecoders)\n",
        "      + \"_\"\n",
        "      + config.optimiser\n",
        "      + \"_\"\n",
        "      + str(config.epochs)\n",
        "      + \"_\"\n",
        "      + str(config.dropout) \n",
        "      + \"_\"\n",
        "      + str(config.batch_size)\n",
        "      + \"_\"\n",
        "      + str(config.latentDim)\n",
        "  )\n",
        "  wandb.run.save()\n",
        "'''\n",
        "  modelInit = Sq2Sq_attention(\n",
        "    config[\"numEncoders\"], \n",
        "    config[\"cell_type\"], \n",
        "    config[\"latentDim\"], \n",
        "    config[\"dropout\"], \n",
        "    config[\"numDecoders\"], \n",
        "    config[\"hidden\"] ,\n",
        "    srcChar2Int=source_char2int, \n",
        "    tgtChar2Int=target_char2int\n",
        "    )\n",
        "\n",
        "  model = modelInit.build_configurable_model()\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=config[\"optimiser\"],\n",
        "      loss=\"categorical_crossentropy\",\n",
        "      metrics=[\"accuracy\"],\n",
        "  )\n",
        "\n",
        "  earlystopping = EarlyStopping(\n",
        "      monitor=\"val_accuracy\", min_delta=0.01, patience=5, verbose=2, mode=\"auto\"\n",
        "  )\n",
        "\n",
        "  model.fit(\n",
        "      [train_encoder_input, train_decoder_input],\n",
        "      train_decoder_target,\n",
        "      batch_size=config[\"batch_size\"],\n",
        "      epochs=config[\"epochs\"],\n",
        "      validation_data=([val_encoder_input, val_decoder_input], val_decoder_target),\n",
        "      callbacks=[earlystopping, WandbCallback()],\n",
        "  )\n",
        "\n",
        "  model.save(os.path.join(\"./TrainedModels\", \"best_model_wo_attn\"))    "
      ],
      "metadata": {
        "id": "sCA1zRiWm8zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMZKRoaDoLXR",
        "outputId": "fadba6fa-9c15-4a33-ae6a-84ab9c7fa078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm_8 (LSTM)                  [(None, None, 256),  290816      ['input_9[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_9 (LSTM)                  [(None, None, 256),  330752      ['input_10[0][0]',               \n",
            "                                 (None, 256),                     'lstm_8[0][1]',                 \n",
            "                                 (None, 256)]                     'lstm_8[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, None, 128)    32896       ['lstm_9[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, None, 66)     8514        ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 662,978\n",
            "Trainable params: 662,978\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1382/1382 [==============================] - 20s 9ms/step - loss: 0.9826 - accuracy: 0.7409 - val_loss: 1.9936 - val_accuracy: 0.6471 - _timestamp: 1652449234.0000 - _runtime: 37.0000\n",
            "Epoch 2/20\n",
            "1382/1382 [==============================] - 12s 8ms/step - loss: 0.7053 - accuracy: 0.7995 - val_loss: 2.0235 - val_accuracy: 0.6712 - _timestamp: 1652449246.0000 - _runtime: 49.0000\n",
            "Epoch 3/20\n",
            "1382/1382 [==============================] - 11s 8ms/step - loss: 0.5407 - accuracy: 0.8425 - val_loss: 1.9607 - val_accuracy: 0.6960 - _timestamp: 1652449257.0000 - _runtime: 60.0000\n",
            "Epoch 4/20\n",
            "1382/1382 [==============================] - 12s 8ms/step - loss: 0.4609 - accuracy: 0.8645 - val_loss: 2.0474 - val_accuracy: 0.7039 - _timestamp: 1652449269.0000 - _runtime: 72.0000\n",
            "Epoch 5/20\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.4155 - accuracy: 0.8767 - val_loss: 2.1676 - val_accuracy: 0.6991 - _timestamp: 1652449282.0000 - _runtime: 85.0000\n",
            "Epoch 6/20\n",
            "1382/1382 [==============================] - 12s 8ms/step - loss: 0.3832 - accuracy: 0.8855 - val_loss: 2.1489 - val_accuracy: 0.7073 - _timestamp: 1652449293.0000 - _runtime: 96.0000\n",
            "Epoch 7/20\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.3589 - accuracy: 0.8923 - val_loss: 2.2373 - val_accuracy: 0.7069 - _timestamp: 1652449305.0000 - _runtime: 108.0000\n",
            "Epoch 8/20\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.3416 - accuracy: 0.8971 - val_loss: 2.1741 - val_accuracy: 0.7157 - _timestamp: 1652449317.0000 - _runtime: 120.0000\n",
            "Epoch 9/20\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.3263 - accuracy: 0.9014 - val_loss: 2.1137 - val_accuracy: 0.7181 - _timestamp: 1652449329.0000 - _runtime: 132.0000\n",
            "Epoch 10/20\n",
            "1382/1382 [==============================] - 12s 8ms/step - loss: 0.3129 - accuracy: 0.9047 - val_loss: 2.2170 - val_accuracy: 0.7068 - _timestamp: 1652449340.0000 - _runtime: 143.0000\n",
            "Epoch 11/20\n",
            "1382/1382 [==============================] - 11s 8ms/step - loss: 0.3048 - accuracy: 0.9074 - val_loss: 2.2328 - val_accuracy: 0.7136 - _timestamp: 1652449352.0000 - _runtime: 155.0000\n",
            "Epoch 12/20\n",
            "1382/1382 [==============================] - 11s 8ms/step - loss: 0.2947 - accuracy: 0.9104 - val_loss: 2.2351 - val_accuracy: 0.7152 - _timestamp: 1652449363.0000 - _runtime: 166.0000\n",
            "Epoch 13/20\n",
            "1382/1382 [==============================] - 11s 8ms/step - loss: 0.2867 - accuracy: 0.9126 - val_loss: 2.1895 - val_accuracy: 0.7157 - _timestamp: 1652449375.0000 - _runtime: 178.0000\n",
            "Epoch 14/20\n",
            "1382/1382 [==============================] - 11s 8ms/step - loss: 0.2806 - accuracy: 0.9143 - val_loss: 2.1557 - val_accuracy: 0.7232 - _timestamp: 1652449386.0000 - _runtime: 189.0000\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedModels/best_model_wo_attn/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedModels/best_model_wo_attn/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f759613dc90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f7597ae69d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "model = tensorflow.keras.models.load_model('/content/TrainedModels/best_model_wo_attn')"
      ],
      "metadata": {
        "id": "3RDuJTDkrr5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRCFgc8LsKfI",
        "outputId": "104a28cf-ea3f-4f77-bb49-93329d319c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm_8 (LSTM)                  [(None, None, 256),  290816      ['input_9[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_9 (LSTM)                  [(None, None, 256),  330752      ['input_10[0][0]',               \n",
            "                                 (None, 256),                     'lstm_8[0][1]',                 \n",
            "                                 (None, 256)]                     'lstm_8[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, None, 128)    32896       ['lstm_9[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, None, 66)     8514        ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 662,978\n",
            "Trainable params: 662,978\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_attn():\n",
        "\n",
        "  config= {\n",
        "      \"cell_type\": \"RNN\",\n",
        "      \"latentDim\": 256,\n",
        "      \"hidden\": 128,\n",
        "      \"optimiser\": \"adam\",\n",
        "      \"numEncoders\": 1,\n",
        "      \"numDecoders\": 3,\n",
        "      \"dropout\": 0.3,\n",
        "      \"epochs\": 20,\n",
        "      \"batch_size\": 64,\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "  modelInit = Sq2Sq_attention(\n",
        "    config[\"numEncoders\"], \n",
        "    config[\"cell_type\"], \n",
        "    config[\"latentDim\"], \n",
        "    config[\"dropout\"], \n",
        "    config[\"numDecoders\"], \n",
        "    config[\"hidden\"] ,\n",
        "    srcChar2Int=source_char2int, \n",
        "    tgtChar2Int=target_char2int\n",
        "    )\n",
        "\n",
        "  model = modelInit.build_attention_model()\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=config[\"optimiser\"],\n",
        "      loss=\"categorical_crossentropy\",\n",
        "      metrics=[\"accuracy\"],\n",
        "  )\n",
        "\n",
        "  earlystopping = EarlyStopping(\n",
        "      monitor=\"val_accuracy\", min_delta=0.01, patience=5, verbose=2, mode=\"auto\"\n",
        "  )\n",
        "\n",
        "  model.fit(\n",
        "      [train_encoder_input, train_decoder_input],\n",
        "      train_decoder_target,\n",
        "      batch_size=config[\"batch_size\"],\n",
        "      epochs=config[\"epochs\"],\n",
        "      validation_data=([val_encoder_input, val_decoder_input], val_decoder_target),\n",
        "      callbacks=[earlystopping, WandbCallback()],\n",
        "  )\n",
        "\n",
        "  model.save(os.path.join(\"./TrainedModels\", \"best_model_attn\"))    "
      ],
      "metadata": {
        "id": "VA-4udWFtS3U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_attn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RNfLo_VBhnd",
        "outputId": "cff561b5-1b2e-4166-c285-ef99a67e0bc4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " simple_rnn (SimpleRNN)         [(None, None, 256),  72704       ['input_1[0][0]']                \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " simple_rnn_3 (SimpleRNN)       [(None, None, 256),  82688       ['input_2[0][0]',                \n",
            "                                 (None, 256)]                     'simple_rnn[0][1]']             \n",
            "                                                                                                  \n",
            " additive_attention (AdditiveAt  (None, None, 256)   256         ['simple_rnn_3[0][0]',           \n",
            " tention)                                                         'simple_rnn[0][0]']             \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 512)    0           ['simple_rnn_3[0][0]',           \n",
            "                                                                  'additive_attention[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 128)    65664       ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 66)     8514        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 229,826\n",
            "Trainable params: 229,826\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "691/691 [==============================] - 39s 44ms/step - loss: 0.9792 - accuracy: 0.7428 - val_loss: 1.6197 - val_accuracy: 0.6743 - _timestamp: 1652587361.0000 - _runtime: 54.0000\n",
            "Epoch 2/20\n",
            "691/691 [==============================] - 27s 39ms/step - loss: 0.7073 - accuracy: 0.8005 - val_loss: 1.6958 - val_accuracy: 0.6924 - _timestamp: 1652587388.0000 - _runtime: 81.0000\n",
            "Epoch 3/20\n",
            "691/691 [==============================] - 27s 39ms/step - loss: 0.6037 - accuracy: 0.8266 - val_loss: 1.6353 - val_accuracy: 0.7038 - _timestamp: 1652587415.0000 - _runtime: 108.0000\n",
            "Epoch 4/20\n",
            "691/691 [==============================] - 31s 44ms/step - loss: 0.5535 - accuracy: 0.8393 - val_loss: 1.6668 - val_accuracy: 0.7073 - _timestamp: 1652587445.0000 - _runtime: 138.0000\n",
            "Epoch 5/20\n",
            "691/691 [==============================] - 29s 42ms/step - loss: 0.5249 - accuracy: 0.8466 - val_loss: 1.6839 - val_accuracy: 0.7192 - _timestamp: 1652587474.0000 - _runtime: 167.0000\n",
            "Epoch 6/20\n",
            "691/691 [==============================] - 27s 40ms/step - loss: 0.5018 - accuracy: 0.8525 - val_loss: 1.7234 - val_accuracy: 0.7084 - _timestamp: 1652587501.0000 - _runtime: 194.0000\n",
            "Epoch 7/20\n",
            "691/691 [==============================] - 29s 43ms/step - loss: 0.4862 - accuracy: 0.8562 - val_loss: 1.6922 - val_accuracy: 0.7213 - _timestamp: 1652587531.0000 - _runtime: 224.0000\n",
            "Epoch 8/20\n",
            "691/691 [==============================] - 27s 39ms/step - loss: 0.4738 - accuracy: 0.8592 - val_loss: 1.6451 - val_accuracy: 0.7340 - _timestamp: 1652587558.0000 - _runtime: 251.0000\n",
            "Epoch 9/20\n",
            "691/691 [==============================] - 26s 38ms/step - loss: 0.4661 - accuracy: 0.8613 - val_loss: 1.7137 - val_accuracy: 0.7282 - _timestamp: 1652587584.0000 - _runtime: 277.0000\n",
            "Epoch 10/20\n",
            "691/691 [==============================] - 27s 38ms/step - loss: 0.4579 - accuracy: 0.8638 - val_loss: 1.6686 - val_accuracy: 0.7416 - _timestamp: 1652587611.0000 - _runtime: 304.0000\n",
            "Epoch 11/20\n",
            "691/691 [==============================] - 26s 38ms/step - loss: 0.4504 - accuracy: 0.8655 - val_loss: 1.5913 - val_accuracy: 0.7390 - _timestamp: 1652587637.0000 - _runtime: 330.0000\n",
            "Epoch 12/20\n",
            "691/691 [==============================] - 26s 38ms/step - loss: 0.4440 - accuracy: 0.8674 - val_loss: 1.7143 - val_accuracy: 0.7397 - _timestamp: 1652587663.0000 - _runtime: 356.0000\n",
            "Epoch 13/20\n",
            "691/691 [==============================] - 26s 38ms/step - loss: 0.4387 - accuracy: 0.8687 - val_loss: 1.7057 - val_accuracy: 0.7383 - _timestamp: 1652587690.0000 - _runtime: 383.0000\n",
            "Epoch 13: early stopping\n",
            "INFO:tensorflow:Assets written to: ./TrainedModels/best_model_attn/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "model_attn = tensorflow.keras.models.load_model('/content/TrainedModels/best_model_attn')"
      ],
      "metadata": {
        "id": "8tJn7K9ZBTT1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def decode_sequence(input_seq,config,encoder_model,decoder_model,target_char2int=target_char2int,target_int2char=target_int2char):\n",
        "            # Encode the input as state vectors.\n",
        "            states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "            # Generate empty target sequence of length 1.\n",
        "            target_seq = np.zeros((1, 1, len(target_char2int)))\n",
        "            # Populate the first character of target sequence with the start character.\n",
        "            target_seq[0, 0, target_char2int[\"\\n\"]] = 1.0\n",
        "\n",
        "            # Sampling loop for a batch of sequences\n",
        "            # (to simplify, here we assume a batch of size 1).\n",
        "            stop_condition = False\n",
        "            decoded_sentence = \"\"\n",
        "            while not stop_condition:\n",
        "                if config[\"cell_type\"] == \"LSTM\":\n",
        "                    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "                elif config[\"cell_type\"] == \"RNN\" or config[\"cell_type\"] == \"GRU\":\n",
        "                    states_value = states_value[0].reshape((1, 256))\n",
        "                    output_tokens, h = decoder_model.predict([target_seq] + [states_value])\n",
        "\n",
        "                # Sample a token\n",
        "                sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "                sampled_char = target_int2char[sampled_token_index]\n",
        "                decoded_sentence += sampled_char\n",
        "\n",
        "                # Exit condition: either hit max length\n",
        "                # or find stop character.\n",
        "                if sampled_char == \"\\n\" or len(decoded_sentence) > 25:\n",
        "                    stop_condition = True\n",
        "\n",
        "                # Update the target sequence (of length 1).\n",
        "                target_seq = np.zeros((1, 1, len(target_char2int)))\n",
        "                target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "                # Update states\n",
        "                if config[\"cell_type\"] == \"LSTM\":\n",
        "                    states_value = [h, c]\n",
        "                elif config[\"cell_type\"] == \"RNN\" or config[\"cell_type\"] == \"GRU\":\n",
        "                    states_value = [h]\n",
        "            return decoded_sentence"
      ],
      "metadata": {
        "id": "Icp263BXdS78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model,target_char2int=target_char2int,target_int2char=target_int2char,attention = False):\n",
        "  if attention == False:\n",
        "    \n",
        "    config = {\n",
        "        \"cell_type\": \"LSTM\",\n",
        "        \"latentDim\": 256,\n",
        "        \"hidden\": 128,\n",
        "        \"optimiser\": \"adam\",\n",
        "        \"numEncoders\": 1,\n",
        "        \"numDecoders\": 1,\n",
        "        \"dropout\": 0.2,\n",
        "        \"epochs\": 20,\n",
        "        \"batch_size\": 32,\n",
        "    }\n",
        "    \n",
        "\n",
        "    encoder_inputs = model.input[0]\n",
        "    \n",
        "    if config[\"numEncoders\"] == 1:\n",
        "        encoder_outputs, state_h_enc, state_c_enc = model.get_layer(name = \"lstm_8\").output \n",
        "    else:           \n",
        "        encoder_outputs, state_h_enc, state_c_enc = model.get_layer(name = \"lstm_\"+ str(config[\"numEncoders\"]-1)).output\n",
        "\n",
        "    encoder_states = [state_h_enc, state_c_enc]\n",
        "    encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_inputs = model.input[1]\n",
        "    decoder_state_input_h = Input(shape=(config[\"latentDim\"],))\n",
        "    decoder_state_input_c = Input(shape=(config[\"latentDim\"],))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    decoder_lstm = model.layers[3]\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm( decoder_inputs, initial_state=decoder_states_inputs )\n",
        "    decoder_states = [state_h_dec, state_c_dec]\n",
        "    decoder_dense = model.layers[-2]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    \n",
        "    decoder_dense = model.layers[-1]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        "    )\n",
        "\n",
        "    acc = 0\n",
        "    sourcelang = []\n",
        "    predictions = []\n",
        "    original = []\n",
        "    for i, row in test.iterrows():\n",
        "        input_seq = test_encoder_input[i : i + 1]\n",
        "        decoded_sentence = decode_sequence(input_seq,config,encoder_model,decoder_model)\n",
        "        \n",
        "        og_tokens = [target_char2int[x] for x in row[\"tgt\"]]\n",
        "        predicted_tokens = [target_char2int[x] for x in decoded_sentence.rstrip(\"\\n\")]\n",
        "        # if decoded_sentence == row['tgt']:\n",
        "        #   acc += 1\n",
        "        sourcelang.append(row['src'])\n",
        "        original.append(row['tgt'])\n",
        "        predictions.append(decoded_sentence)\n",
        "\n",
        "        if og_tokens == predicted_tokens:\n",
        "            acc += 1\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Finished {i} examples\")\n",
        "            print(f\"Source: {row['src']}\")\n",
        "            print(f\"Original: {row['tgt']}\")\n",
        "            print(f\"Predicted: {decoded_sentence}\")\n",
        "            print(f\"Accuracy: {acc / (i+1)}\")\n",
        "            print(og_tokens)\n",
        "            print(predicted_tokens)\n",
        "            \n",
        "\n",
        "    print(f'Test Accuracy: {acc}')\n",
        "    #wandb.log({'test_accuracy': acc / len(test)})\n",
        "    #wandb.finish()\n",
        "    return acc / len(test), sourcelang, original, predictions"
      ],
      "metadata": {
        "id": "l_b7lpNBdTe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc,lang,org,pred=test_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1Aha1hRr_aP",
        "outputId": "aa177b49-7192-489a-f138-f605c9b952d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished 0 examples\n",
            "Source: ank\n",
            "Original: अंक\n",
            "Predicted: अंक\n",
            "\n",
            "Accuracy: 1.0\n",
            "[5, 3, 17]\n",
            "[5, 3, 17]\n",
            "Finished 100 examples\n",
            "Source: anukulata\n",
            "Original: अनुकूलता\n",
            "Predicted: अनुकुलता\n",
            "\n",
            "Accuracy: 0.2079207920792079\n",
            "[5, 36, 54, 17, 55, 44, 32, 51]\n",
            "[5, 36, 54, 17, 54, 44, 32, 51]\n",
            "Finished 200 examples\n",
            "Source: avaru\n",
            "Original: अवरु\n",
            "Predicted: अवरू\n",
            "\n",
            "Accuracy: 0.263681592039801\n",
            "[5, 45, 43, 54]\n",
            "[5, 45, 43, 55]\n",
            "Finished 300 examples\n",
            "Source: aabru\n",
            "Original: आबरू\n",
            "Predicted: आबरू\n",
            "\n",
            "Accuracy: 0.30564784053156147\n",
            "[6, 39, 43, 55]\n",
            "[6, 39, 43, 55]\n",
            "Finished 400 examples\n",
            "Source: inhaletion\n",
            "Original: इनहेलेशन\n",
            "Predicted: इंहलेशन\n",
            "\n",
            "Accuracy: 0.2793017456359102\n",
            "[7, 36, 49, 58, 44, 58, 46, 36]\n",
            "[7, 3, 49, 44, 58, 46, 36]\n",
            "Finished 500 examples\n",
            "Source: umesh\n",
            "Original: उमेश\n",
            "Predicted: उमेश\n",
            "\n",
            "Accuracy: 0.26746506986027946\n",
            "[9, 41, 58, 46]\n",
            "[9, 41, 58, 46]\n",
            "Finished 600 examples\n",
            "Source: asphalt\n",
            "Original: एस्फाल्ट\n",
            "Predicted: असफलत\n",
            "\n",
            "Accuracy: 0.2545757071547421\n",
            "[12, 48, 63, 38, 51, 44, 63, 27]\n",
            "[5, 48, 38, 44, 32]\n",
            "Finished 700 examples\n",
            "Source: kaping\n",
            "Original: कपिंग\n",
            "Predicted: कापिंग\n",
            "\n",
            "Accuracy: 0.24536376604850213\n",
            "[17, 37, 52, 3, 19]\n",
            "[17, 51, 37, 52, 3, 19]\n",
            "Finished 800 examples\n",
            "Source: kasim\n",
            "Original: कासिम\n",
            "Predicted: कसीम\n",
            "\n",
            "Accuracy: 0.2571785268414482\n",
            "[17, 51, 48, 52, 41]\n",
            "[17, 48, 53, 41]\n",
            "Finished 900 examples\n",
            "Source: kshitij\n",
            "Original: क्षितिज\n",
            "Predicted: क्षितिज\n",
            "\n",
            "Accuracy: 0.2586015538290788\n",
            "[17, 63, 47, 52, 32, 52, 24]\n",
            "[17, 63, 47, 52, 32, 52, 24]\n",
            "Finished 1000 examples\n",
            "Source: girjagharon\n",
            "Original: गिरजाघरों\n",
            "Predicted: गिर्जाहारियों\n",
            "\n",
            "Accuracy: 0.26373626373626374\n",
            "[19, 52, 43, 24, 51, 20, 43, 61, 3]\n",
            "[19, 52, 43, 63, 24, 51, 49, 51, 43, 52, 42, 61, 3]\n",
            "Finished 1100 examples\n",
            "Source: chatushkoniy\n",
            "Original: चतुष्कोणीय\n",
            "Predicted: चतुत्योकीय\n",
            "\n",
            "Accuracy: 0.26793823796548594\n",
            "[22, 32, 54, 47, 63, 17, 61, 31, 53, 42]\n",
            "[22, 32, 54, 32, 63, 42, 61, 17, 53, 42]\n",
            "Finished 1200 examples\n",
            "Source: chhagla\n",
            "Original: छागला\n",
            "Predicted: छागला\n",
            "\n",
            "Accuracy: 0.2681099084096586\n",
            "[23, 51, 19, 44, 51]\n",
            "[23, 51, 19, 44, 51]\n",
            "Finished 1300 examples\n",
            "Source: jalagati\n",
            "Original: जलगति\n",
            "Predicted: जलागती\n",
            "\n",
            "Accuracy: 0.26210607225211374\n",
            "[24, 44, 19, 32, 52]\n",
            "[24, 44, 51, 19, 32, 53]\n",
            "Finished 1400 examples\n",
            "Source: jue\n",
            "Original: जुए\n",
            "Predicted: जुए\n",
            "\n",
            "Accuracy: 0.2740899357601713\n",
            "[24, 54, 12]\n",
            "[24, 54, 12]\n",
            "Finished 1500 examples\n",
            "Source: tau\n",
            "Original: टाऊ\n",
            "Predicted: ताऊ\n",
            "\n",
            "Accuracy: 0.279147235176549\n",
            "[27, 51, 10]\n",
            "[32, 51, 10]\n",
            "Finished 1600 examples\n",
            "Source: dulne\n",
            "Original: डुलने\n",
            "Predicted: दुलने\n",
            "\n",
            "Accuracy: 0.2704559650218613\n",
            "[29, 54, 44, 36, 58]\n",
            "[34, 54, 44, 36, 58]\n",
            "Finished 1700 examples\n",
            "Source: tapmano\n",
            "Original: तापमानों\n",
            "Predicted: तपमानों\n",
            "\n",
            "Accuracy: 0.27336860670194\n",
            "[32, 51, 37, 41, 51, 36, 61, 3]\n",
            "[32, 37, 41, 51, 36, 61, 3]\n",
            "Finished 1800 examples\n",
            "Source: dahal\n",
            "Original: दहल\n",
            "Predicted: दहाल\n",
            "\n",
            "Accuracy: 0.27151582454192114\n",
            "[34, 49, 44]\n",
            "[34, 49, 51, 44]\n",
            "Finished 1900 examples\n",
            "Source: devapur\n",
            "Original: देवापुर\n",
            "Predicted: देवापुर\n",
            "\n",
            "Accuracy: 0.2824829037348764\n",
            "[34, 58, 45, 51, 37, 54, 43]\n",
            "[34, 58, 45, 51, 37, 54, 43]\n",
            "Finished 2000 examples\n",
            "Source: najariyon\n",
            "Original: नजरियों\n",
            "Predicted: नजरियों\n",
            "\n",
            "Accuracy: 0.2813593203398301\n",
            "[36, 24, 43, 52, 42, 61, 3]\n",
            "[36, 24, 43, 52, 42, 61, 3]\n",
            "Finished 2100 examples\n",
            "Source: nipatara\n",
            "Original: निपटारा\n",
            "Predicted: निपटतर\n",
            "\n",
            "Accuracy: 0.28557829604950025\n",
            "[36, 52, 37, 27, 51, 43, 51]\n",
            "[36, 52, 37, 27, 32, 43]\n",
            "Finished 2200 examples\n",
            "Source: patkathaein\n",
            "Original: पटकथाएं\n",
            "Predicted: पट्टकहाएं\n",
            "\n",
            "Accuracy: 0.29259427532939575\n",
            "[37, 27, 17, 33, 51, 12, 3]\n",
            "[37, 27, 63, 27, 17, 49, 51, 12, 3]\n",
            "Finished 2300 examples\n",
            "Source: paathshaalaayein\n",
            "Original: पाठशालाएं\n",
            "Predicted: पर्शगवाली\n",
            "\n",
            "Accuracy: 0.2985658409387223\n",
            "[37, 51, 28, 46, 51, 44, 51, 12, 3]\n",
            "[37, 43, 63, 46, 19, 45, 51, 44, 53]\n",
            "Finished 2400 examples\n",
            "Source: pushpa\n",
            "Original: पुष्पा\n",
            "Predicted: पुष्पा\n",
            "\n",
            "Accuracy: 0.29737609329446063\n",
            "[37, 54, 47, 63, 37, 51]\n",
            "[37, 54, 47, 63, 37, 51]\n",
            "Finished 2500 examples\n",
            "Source: prathmikta\n",
            "Original: प्राथमिकता\n",
            "Predicted: प्रामिकिकता\n",
            "\n",
            "Accuracy: 0.29868052778888443\n",
            "[37, 63, 43, 51, 33, 41, 52, 17, 32, 51]\n",
            "[37, 63, 43, 51, 41, 52, 17, 52, 17, 32, 51]\n",
            "Finished 2600 examples\n",
            "Source: firti\n",
            "Original: फिरती\n",
            "Predicted: फर्टी\n",
            "\n",
            "Accuracy: 0.29565551710880433\n",
            "[38, 52, 43, 32, 53]\n",
            "[38, 43, 63, 27, 53]\n",
            "Finished 2700 examples\n",
            "Source: batlaye\n",
            "Original: बतलाए\n",
            "Predicted: बतलाए\n",
            "\n",
            "Accuracy: 0.29803776379118846\n",
            "[39, 32, 44, 51, 12]\n",
            "[39, 32, 44, 51, 12]\n",
            "Finished 2800 examples\n",
            "Source: baalti\n",
            "Original: बाल्टी\n",
            "Predicted: बालती\n",
            "\n",
            "Accuracy: 0.3041770796144234\n",
            "[39, 51, 44, 63, 27, 53]\n",
            "[39, 51, 44, 32, 53]\n",
            "Finished 2900 examples\n",
            "Source: bodra\n",
            "Original: बोदरा\n",
            "Predicted: बोद्रा\n",
            "\n",
            "Accuracy: 0.3054119269217511\n",
            "[39, 61, 34, 43, 51]\n",
            "[39, 61, 34, 63, 43, 51]\n",
            "Finished 3000 examples\n",
            "Source: bhulo\n",
            "Original: भूलो\n",
            "Predicted: भूलो\n",
            "\n",
            "Accuracy: 0.30756414528490506\n",
            "[40, 55, 44, 61]\n",
            "[40, 55, 44, 61]\n",
            "Finished 3100 examples\n",
            "Source: mahkane\n",
            "Original: महकने\n",
            "Predicted: महकाने\n",
            "\n",
            "Accuracy: 0.3105449854885521\n",
            "[41, 49, 17, 36, 58]\n",
            "[41, 49, 17, 51, 36, 58]\n",
            "Finished 3200 examples\n",
            "Source: mubarkpur\n",
            "Original: मुबारकपुर\n",
            "Predicted: मुबाकपुर\n",
            "\n",
            "Accuracy: 0.3136519837550765\n",
            "[41, 54, 39, 51, 43, 17, 37, 54, 43]\n",
            "[41, 54, 39, 51, 17, 37, 54, 43]\n",
            "Finished 3300 examples\n",
            "Source: mohani\n",
            "Original: मोहानी\n",
            "Predicted: मोहनी\n",
            "\n",
            "Accuracy: 0.3153589821266283\n",
            "[41, 61, 49, 51, 36, 53]\n",
            "[41, 61, 49, 36, 53]\n",
            "Finished 3400 examples\n",
            "Source: rajman\n",
            "Original: राजमां\n",
            "Predicted: राजमान\n",
            "\n",
            "Accuracy: 0.31608350485151426\n",
            "[43, 51, 24, 41, 51, 3]\n",
            "[43, 51, 24, 41, 51, 36]\n",
            "Finished 3500 examples\n",
            "Source: reshey\n",
            "Original: रेशे\n",
            "Predicted: रेशे\n",
            "\n",
            "Accuracy: 0.319908597543559\n",
            "[43, 58, 46, 58]\n",
            "[43, 58, 46, 58]\n",
            "Finished 3600 examples\n",
            "Source: lanchar\n",
            "Original: लांचर\n",
            "Predicted: लांचार\n",
            "\n",
            "Accuracy: 0.3210219383504582\n",
            "[44, 51, 3, 22, 43]\n",
            "[44, 51, 3, 22, 51, 43]\n",
            "Finished 3700 examples\n",
            "Source: varnit\n",
            "Original: वर्णित\n",
            "Predicted: वर्णित\n",
            "\n",
            "Accuracy: 0.3196433396379357\n",
            "[45, 43, 63, 31, 52, 32]\n",
            "[45, 43, 63, 31, 52, 32]\n",
            "Finished 3800 examples\n",
            "Source: vimarshon\n",
            "Original: विमर्शों\n",
            "Predicted: विमारशों\n",
            "\n",
            "Accuracy: 0.32070507761115497\n",
            "[45, 52, 41, 43, 63, 46, 61, 3]\n",
            "[45, 52, 41, 51, 43, 46, 61, 3]\n",
            "Finished 3900 examples\n",
            "Source: shamitabh\n",
            "Original: शमिताभ\n",
            "Predicted: श्रमिभा\n",
            "\n",
            "Accuracy: 0.3199179697513458\n",
            "[46, 41, 52, 32, 51, 40]\n",
            "[46, 63, 43, 41, 52, 40, 51]\n",
            "Finished 4000 examples\n",
            "Source: samprbhuta\n",
            "Original: संप्रभुता\n",
            "Predicted: संप्रभूता\n",
            "\n",
            "Accuracy: 0.3211697075731067\n",
            "[48, 3, 37, 63, 43, 40, 54, 32, 51]\n",
            "[48, 3, 37, 63, 43, 40, 55, 32, 51]\n",
            "Finished 4100 examples\n",
            "Source: sargana\n",
            "Original: सरगना\n",
            "Predicted: सरगाना\n",
            "\n",
            "Accuracy: 0.32016581321628873\n",
            "[48, 43, 19, 36, 51]\n",
            "[48, 43, 19, 51, 36, 51]\n",
            "Finished 4200 examples\n",
            "Source: simate\n",
            "Original: सिमटे\n",
            "Predicted: सिमाते\n",
            "\n",
            "Accuracy: 0.31801951916210425\n",
            "[48, 52, 41, 27, 58]\n",
            "[48, 52, 41, 51, 32, 58]\n",
            "Finished 4300 examples\n",
            "Source: self\n",
            "Original: सेल्फ\n",
            "Predicted: सेल्फ\n",
            "\n",
            "Accuracy: 0.3192280864915136\n",
            "[48, 58, 44, 63, 38]\n",
            "[48, 58, 44, 63, 38]\n",
            "Finished 4400 examples\n",
            "Source: sweet\n",
            "Original: स्वीट\n",
            "Predicted: स्वीत\n",
            "\n",
            "Accuracy: 0.31742785730515793\n",
            "[48, 63, 45, 53, 27]\n",
            "[48, 63, 45, 53, 32]\n",
            "Finished 4500 examples\n",
            "Source: hostes\n",
            "Original: होस्टेस\n",
            "Predicted: हॉस्टर्स\n",
            "\n",
            "Accuracy: 0.3181515218840258\n",
            "[49, 61, 48, 63, 27, 58, 48]\n",
            "[49, 60, 48, 63, 27, 43, 63, 48]\n",
            "Test Accuracy: 1432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy of model without attention\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wvBoe4hTwsp",
        "outputId": "b1677f0a-67d2-4bb9-c432-c12d1060e146"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3054119269217511"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict2 = [{\"input\":lang[i], \"true\": org[i], \"predicted\": pred[i]} for i in range(len(lang))] \n",
        "test_predictions = pd.DataFrame(dict2)\n",
        "test_predictions.to_csv('predictions_without_attn.csv', index=False, sep='\\t')"
      ],
      "metadata": {
        "id": "dyVfDSw7vP6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XSbwbldJidiB",
        "outputId": "da4be63e-cdef-426d-ad39-ed7224c1a364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             input       true   predicted\n",
              "0              ank        अंक       अंक\\n\n",
              "1             anka        अंक      अंका\\n\n",
              "2            ankit      अंकित     अंकित\\n\n",
              "3           anakon      अंकों     अनकों\\n\n",
              "4           ankhon      अंकों     अंखों\\n\n",
              "...            ...        ...         ...\n",
              "4497       holding   होल्डिंग    हॉलिंग\\n\n",
              "4498  hoshangabaad  होशंगाबाद  होशनाबाद\\n\n",
              "4499   hoshangabad  होशंगाबाद  होशनाबाद\\n\n",
              "4500        hostes    होस्टेस  हॉस्टर्स\\n\n",
              "4501       hostess    होस्टेस   हॉस्ट्स\\n\n",
              "\n",
              "[4502 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7c7ea08-5db4-4d7c-8a8c-c80a99a440b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>true</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ank</td>\n",
              "      <td>अंक</td>\n",
              "      <td>अंक\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anka</td>\n",
              "      <td>अंक</td>\n",
              "      <td>अंका\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ankit</td>\n",
              "      <td>अंकित</td>\n",
              "      <td>अंकित\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>anakon</td>\n",
              "      <td>अंकों</td>\n",
              "      <td>अनकों\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ankhon</td>\n",
              "      <td>अंकों</td>\n",
              "      <td>अंखों\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4497</th>\n",
              "      <td>holding</td>\n",
              "      <td>होल्डिंग</td>\n",
              "      <td>हॉलिंग\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4498</th>\n",
              "      <td>hoshangabaad</td>\n",
              "      <td>होशंगाबाद</td>\n",
              "      <td>होशनाबाद\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4499</th>\n",
              "      <td>hoshangabad</td>\n",
              "      <td>होशंगाबाद</td>\n",
              "      <td>होशनाबाद\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4500</th>\n",
              "      <td>hostes</td>\n",
              "      <td>होस्टेस</td>\n",
              "      <td>हॉस्टर्स\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4501</th>\n",
              "      <td>hostess</td>\n",
              "      <td>होस्टेस</td>\n",
              "      <td>हॉस्ट्स\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4502 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7c7ea08-5db4-4d7c-8a8c-c80a99a440b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7c7ea08-5db4-4d7c-8a8c-c80a99a440b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7c7ea08-5db4-4d7c-8a8c-c80a99a440b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_attn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MbSPDXrBTZs",
        "outputId": "e3589536-9772-4604-84da-dfcfcc6ee98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " simple_rnn_1 (SimpleRNN)       [(None, None, 256),  72704       ['input_2[0][0]']                \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " simple_rnn_4 (SimpleRNN)       [(None, None, 256),  82688       ['input_3[0][0]',                \n",
            "                                 (None, 256)]                     'simple_rnn_1[0][1]']           \n",
            "                                                                                                  \n",
            " additive_attention (AdditiveAt  (None, None, 256)   256         ['simple_rnn_4[0][0]',           \n",
            " tention)                                                         'simple_rnn_1[0][0]']           \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 512)    0           ['simple_rnn_4[0][0]',           \n",
            "                                                                  'additive_attention[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 128)    65664       ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 66)     8514        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 229,826\n",
            "Trainable params: 229,826\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_attn.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwNVZozN-FaA",
        "outputId": "c35a6184-4aa5-4b47-f6c7-5f4e99b279f1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " simple_rnn (SimpleRNN)         [(None, None, 256),  72704       ['input_1[0][0]']                \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " simple_rnn_3 (SimpleRNN)       [(None, None, 256),  82688       ['input_2[0][0]',                \n",
            "                                 (None, 256)]                     'simple_rnn[0][1]']             \n",
            "                                                                                                  \n",
            " additive_attention (AdditiveAt  (None, None, 256)   256         ['simple_rnn_3[0][0]',           \n",
            " tention)                                                         'simple_rnn[0][0]']             \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 512)    0           ['simple_rnn_3[0][0]',           \n",
            "                                                                  'additive_attention[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 128)    65664       ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 66)     8514        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 229,826\n",
            "Trainable params: 229,826\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "      \"cell_type\": \"RNN\",\n",
        "      \"latentDim\": 256,\n",
        "      \"hidden\": 128,\n",
        "      \"optimiser\": \"adam\",\n",
        "      \"numEncoders\": 1,\n",
        "      \"numDecoders\": 3,\n",
        "      \"dropout\": 0.3,\n",
        "      \"epochs\": 20,\n",
        "      \"batch_size\": 64,\n",
        "  }"
      ],
      "metadata": {
        "id": "Bta3Ocnq-qrD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=model_attn\n",
        "encoder_inputs = model.input[0]\n",
        "if config['numEncoders'] == 1:\n",
        "    encoder_outputs, state = model.get_layer(name = \"simple_rnn\").output\n",
        "else:\n",
        "    encoder_outputs, state = model.get_layer(name = \"simple_rnn_\"+ str(config['numEncoders']-1)).output\n",
        "encoder_first_outputs, _ = model.get_layer(name = \"simple_rnn\").output\n",
        "encoder_states = [state]\n",
        "\n",
        "encoder_model = Model(encoder_inputs, outputs = [encoder_first_outputs, encoder_outputs] + encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]\n",
        "\n",
        "decoder_state = Input(shape=(config['latentDim'],), name=\"input_3\")\n",
        "decoder_hidden_state = Input(shape=(None,config[\"latentDim\"]), name = \"input_4\")\n",
        "decoder_states_inputs = [decoder_state]\n",
        "\n",
        "decoder_gru = model.get_layer(name = \"simple_rnn_\"+ str(config['numEncoders'] + config['numDecoders'] -1))#model.layers[-3]\n",
        "(decoder_outputs, state) = decoder_gru(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state]\n",
        "\n",
        "            \n",
        "attention_layer = model.get_layer(name='additive_attention')\n",
        "    #decoder_outputs_att = decoder_ouputs\n",
        "attention_out = attention_layer([decoder_outputs,decoder_hidden_state])\n",
        "\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_out])\n",
        "\n",
        "decoder_dense = model.layers[-2]\n",
        "decoder_time = TimeDistributed(decoder_dense)\n",
        "hidden_outputs = decoder_time(decoder_concat_input)\n",
        "decoder_dense = model.layers[-1]\n",
        "decoder_outputs = decoder_dense(hidden_outputs)\n",
        "\n",
        "decoder_model = Model(inputs = [decoder_inputs] + [decoder_hidden_state , decoder_states_inputs], outputs = [decoder_outputs] + decoder_states)\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "z6tF-VRfVXEH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence_attn(input_seq,target_char2int=target_char2int,target_int2char=target_int2char):\n",
        "    # Encode the input as state vectors.\n",
        "    encoder_first_outputs, _, states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, len(target_char2int)))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_char2int[\"\\n\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    attention_weights = []\n",
        "    while not stop_condition:\n",
        "        if config['cell_type'] == \"LSTM\":\n",
        "            output_tokens, h, c = decoder_model.predict([target_seq, encoder_first_outputs] + states_value)\n",
        "        elif config['cell_type'] == \"RNN\" or config['cell_type'] == \"GRU\":\n",
        "            states_value = states_value[0].reshape((1, config['latentDim']))\n",
        "            output_tokens, h = decoder_model.predict([target_seq] + [encoder_first_outputs] + [states_value])\n",
        "        #dec_ind = np.argmax(output_tokens, axis=-1)[0, 0]\n",
        "        #attention_weights.append((dec_ind, attn_states))\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = target_int2char[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > 25:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, len(target_char2int)))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        if config['cell_type'] == \"LSTM\":\n",
        "            states_value = [h, c]\n",
        "        elif config['cell_type'] == \"RNN\" or config['cell_type'] == \"GRU\":\n",
        "            states_value = [h]\n",
        "    return decoded_sentence #, attention_weights\n",
        "\n"
      ],
      "metadata": {
        "id": "jMSq-SQqAXzA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = 0\n",
        "sourcelang = []\n",
        "predictions = []\n",
        "original = []\n",
        "#attention_weights_test = []\n",
        "for i, row in test.iterrows():\n",
        "    input_seq = test_encoder_input[i : i + 1]\n",
        "    decoded_sentence = decode_sequence_attn(input_seq,target_char2int=target_char2int,target_int2char=target_int2char)\n",
        "    og_tokens = [target_char2int[x] for x in row[\"tgt\"]]\n",
        "    predicted_tokens = [target_char2int[x] for x in decoded_sentence.rstrip(\"\\n\")]\n",
        "    # if decoded_sentence == row['tgt']:\n",
        "    #   acc += 1\n",
        "    sourcelang.append(row['src'])\n",
        "    original.append(row['tgt'])\n",
        "    predictions.append(decoded_sentence)\n",
        "    #attention_weights_test.append(attention_weights)\n",
        "    if og_tokens == predicted_tokens:\n",
        "        acc += 1\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Finished {i} examples\")\n",
        "        print(f\"Source: {row['src']}\")\n",
        "        print(f\"Original: {row['tgt']}\")\n",
        "        print(f\"Predicted: {decoded_sentence}\")\n",
        "        print(f\"Accuracy: {acc / (i+1)}\")\n",
        "        print(og_tokens)\n",
        "        print(predicted_tokens)\n",
        "        \n",
        "\n",
        "print(f'Test Accuracy: {acc}')\n",
        "\n",
        "accuracy= acc / len(test)  \n",
        "lang=sourcelang\n",
        "org=original\n",
        "pred=predictions #,\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hvK9tLUAdmR",
        "outputId": "1cd4b96f-84a4-4285-ceec-5c94177ae15f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished 0 examples\n",
            "Source: ank\n",
            "Original: अंक\n",
            "Predicted: आंक\n",
            "\n",
            "Accuracy: 0.0\n",
            "[5, 3, 17]\n",
            "[6, 3, 17]\n",
            "Finished 100 examples\n",
            "Source: anukulata\n",
            "Original: अनुकूलता\n",
            "Predicted: आनुकुलता\n",
            "\n",
            "Accuracy: 0.0\n",
            "[5, 36, 54, 17, 55, 44, 32, 51]\n",
            "[6, 36, 54, 17, 54, 44, 32, 51]\n",
            "Finished 200 examples\n",
            "Source: avaru\n",
            "Original: अवरु\n",
            "Predicted: आवरू\n",
            "\n",
            "Accuracy: 0.014925373134328358\n",
            "[5, 45, 43, 54]\n",
            "[6, 45, 43, 55]\n",
            "Finished 300 examples\n",
            "Source: aabru\n",
            "Original: आबरू\n",
            "Predicted: आभ्रु\n",
            "\n",
            "Accuracy: 0.06312292358803986\n",
            "[6, 39, 43, 55]\n",
            "[6, 40, 63, 43, 54]\n",
            "Finished 400 examples\n",
            "Source: inhaletion\n",
            "Original: इनहेलेशन\n",
            "Predicted: इनहालेतियों\n",
            "\n",
            "Accuracy: 0.11471321695760599\n",
            "[7, 36, 49, 58, 44, 58, 46, 36]\n",
            "[7, 36, 49, 51, 44, 58, 32, 52, 42, 61, 3]\n",
            "Finished 500 examples\n",
            "Source: umesh\n",
            "Original: उमेश\n",
            "Predicted: उमेश\n",
            "\n",
            "Accuracy: 0.1437125748502994\n",
            "[9, 41, 58, 46]\n",
            "[9, 41, 58, 46]\n",
            "Finished 600 examples\n",
            "Source: asphalt\n",
            "Original: एस्फाल्ट\n",
            "Predicted: आस्पल्त\n",
            "\n",
            "Accuracy: 0.1314475873544093\n",
            "[12, 48, 63, 38, 51, 44, 63, 27]\n",
            "[6, 48, 63, 37, 44, 63, 32]\n",
            "Finished 700 examples\n",
            "Source: kaping\n",
            "Original: कपिंग\n",
            "Predicted: कपिंग\n",
            "\n",
            "Accuracy: 0.12553495007132667\n",
            "[17, 37, 52, 3, 19]\n",
            "[17, 37, 52, 3, 19]\n",
            "Finished 800 examples\n",
            "Source: kasim\n",
            "Original: कासिम\n",
            "Predicted: कासीम\n",
            "\n",
            "Accuracy: 0.12983770287141075\n",
            "[17, 51, 48, 52, 41]\n",
            "[17, 51, 48, 53, 41]\n",
            "Finished 900 examples\n",
            "Source: kshitij\n",
            "Original: क्षितिज\n",
            "Predicted: क्षितिज\n",
            "\n",
            "Accuracy: 0.14428412874583796\n",
            "[17, 63, 47, 52, 32, 52, 24]\n",
            "[17, 63, 47, 52, 32, 52, 24]\n",
            "Finished 1000 examples\n",
            "Source: girjagharon\n",
            "Original: गिरजाघरों\n",
            "Predicted: गीरजगढ़ों\n",
            "\n",
            "Accuracy: 0.13686313686313686\n",
            "[19, 52, 43, 24, 51, 20, 43, 61, 3]\n",
            "[19, 53, 43, 24, 19, 30, 50, 61, 3]\n",
            "Finished 1100 examples\n",
            "Source: chatushkoniy\n",
            "Original: चतुष्कोणीय\n",
            "Predicted: चातुष्कों\n",
            "\n",
            "Accuracy: 0.14168937329700274\n",
            "[22, 32, 54, 47, 63, 17, 61, 31, 53, 42]\n",
            "[22, 51, 32, 54, 47, 63, 17, 61, 3]\n",
            "Finished 1200 examples\n",
            "Source: chhagla\n",
            "Original: छागला\n",
            "Predicted: छगाला\n",
            "\n",
            "Accuracy: 0.1440466278101582\n",
            "[23, 51, 19, 44, 51]\n",
            "[23, 19, 51, 44, 51]\n",
            "Finished 1300 examples\n",
            "Source: jalagati\n",
            "Original: जलगति\n",
            "Predicted: जलागती\n",
            "\n",
            "Accuracy: 0.15295926210607225\n",
            "[24, 44, 19, 32, 52]\n",
            "[24, 44, 51, 19, 32, 53]\n",
            "Finished 1400 examples\n",
            "Source: jue\n",
            "Original: जुए\n",
            "Predicted: जुए\n",
            "\n",
            "Accuracy: 0.15845824411134904\n",
            "[24, 54, 12]\n",
            "[24, 54, 12]\n",
            "Finished 1500 examples\n",
            "Source: tau\n",
            "Original: टाऊ\n",
            "Predicted: तौ\n",
            "\n",
            "Accuracy: 0.15922718187874751\n",
            "[27, 51, 10]\n",
            "[32, 62]\n",
            "Finished 1600 examples\n",
            "Source: dulne\n",
            "Original: डुलने\n",
            "Predicted: दुलने\n",
            "\n",
            "Accuracy: 0.15302935665209244\n",
            "[29, 54, 44, 36, 58]\n",
            "[34, 54, 44, 36, 58]\n",
            "Finished 1700 examples\n",
            "Source: tapmano\n",
            "Original: तापमानों\n",
            "Predicted: तप्माणों\n",
            "\n",
            "Accuracy: 0.15285126396237508\n",
            "[32, 51, 37, 41, 51, 36, 61, 3]\n",
            "[32, 37, 63, 41, 51, 31, 61, 3]\n",
            "Finished 1800 examples\n",
            "Source: dahal\n",
            "Original: दहल\n",
            "Predicted: दहाल\n",
            "\n",
            "Accuracy: 0.15935591338145474\n",
            "[34, 49, 44]\n",
            "[34, 49, 51, 44]\n",
            "Finished 1900 examples\n",
            "Source: devapur\n",
            "Original: देवापुर\n",
            "Predicted: देवापुर\n",
            "\n",
            "Accuracy: 0.16780641767490795\n",
            "[34, 58, 45, 51, 37, 54, 43]\n",
            "[34, 58, 45, 51, 37, 54, 43]\n",
            "Finished 2000 examples\n",
            "Source: najariyon\n",
            "Original: नजरियों\n",
            "Predicted: नज़रियों\n",
            "\n",
            "Accuracy: 0.17391304347826086\n",
            "[36, 24, 43, 52, 42, 61, 3]\n",
            "[36, 24, 50, 43, 52, 42, 61, 3]\n",
            "Finished 2100 examples\n",
            "Source: nipatara\n",
            "Original: निपटारा\n",
            "Predicted: निपातारा\n",
            "\n",
            "Accuracy: 0.17801047120418848\n",
            "[36, 52, 37, 27, 51, 43, 51]\n",
            "[36, 52, 37, 51, 32, 51, 43, 51]\n",
            "Finished 2200 examples\n",
            "Source: patkathaein\n",
            "Original: पटकथाएं\n",
            "Predicted: पत्काताएं\n",
            "\n",
            "Accuracy: 0.18491594729668331\n",
            "[37, 27, 17, 33, 51, 12, 3]\n",
            "[37, 32, 63, 17, 51, 32, 51, 12, 3]\n",
            "Finished 2300 examples\n",
            "Source: paathshaalaayein\n",
            "Original: पाठशालाएं\n",
            "Predicted:                           \n",
            "Accuracy: 0.18339852238157323\n",
            "[37, 51, 28, 46, 51, 44, 51, 12, 3]\n",
            "[65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65]\n",
            "Finished 2400 examples\n",
            "Source: pushpa\n",
            "Original: पुष्पा\n",
            "Predicted: पुष्पा\n",
            "\n",
            "Accuracy: 0.18075801749271136\n",
            "[37, 54, 47, 63, 37, 51]\n",
            "[37, 54, 47, 63, 37, 51]\n",
            "Finished 2500 examples\n",
            "Source: prathmikta\n",
            "Original: प्राथमिकता\n",
            "Predicted: प्रत्मिक्ता\n",
            "\n",
            "Accuracy: 0.18512594962015194\n",
            "[37, 63, 43, 51, 33, 41, 52, 17, 32, 51]\n",
            "[37, 63, 43, 32, 63, 41, 52, 17, 63, 32, 51]\n",
            "Finished 2600 examples\n",
            "Source: firti\n",
            "Original: फिरती\n",
            "Predicted: फीरती\n",
            "\n",
            "Accuracy: 0.18531334102268357\n",
            "[38, 52, 43, 32, 53]\n",
            "[38, 53, 43, 32, 53]\n",
            "Finished 2700 examples\n",
            "Source: batlaye\n",
            "Original: बतलाए\n",
            "Predicted: बत्लाये\n",
            "\n",
            "Accuracy: 0.18659755646057016\n",
            "[39, 32, 44, 51, 12]\n",
            "[39, 32, 63, 44, 51, 42, 58]\n",
            "Finished 2800 examples\n",
            "Source: baalti\n",
            "Original: बाल्टी\n",
            "Predicted: बालती\n",
            "\n",
            "Accuracy: 0.18636201356658336\n",
            "[39, 51, 44, 63, 27, 53]\n",
            "[39, 51, 44, 32, 53]\n",
            "Finished 2900 examples\n",
            "Source: bodra\n",
            "Original: बोदरा\n",
            "Predicted: बोदरा\n",
            "\n",
            "Accuracy: 0.19027921406411583\n",
            "[39, 61, 34, 43, 51]\n",
            "[39, 61, 34, 43, 51]\n",
            "Finished 3000 examples\n",
            "Source: bhulo\n",
            "Original: भूलो\n",
            "Predicted: भूलो\n",
            "\n",
            "Accuracy: 0.19360213262245918\n",
            "[40, 55, 44, 61]\n",
            "[40, 55, 44, 61]\n",
            "Finished 3100 examples\n",
            "Source: mahkane\n",
            "Original: महकने\n",
            "Predicted: महकाने\n",
            "\n",
            "Accuracy: 0.1944534021283457\n",
            "[41, 49, 17, 36, 58]\n",
            "[41, 49, 17, 51, 36, 58]\n",
            "Finished 3200 examples\n",
            "Source: mubarkpur\n",
            "Original: मुबारकपुर\n",
            "Predicted: मुबार्पुर\n",
            "\n",
            "Accuracy: 0.19837550765385817\n",
            "[41, 54, 39, 51, 43, 17, 37, 54, 43]\n",
            "[41, 54, 39, 51, 43, 63, 37, 54, 43]\n",
            "Finished 3300 examples\n",
            "Source: mohani\n",
            "Original: मोहानी\n",
            "Predicted: मोहनी\n",
            "\n",
            "Accuracy: 0.19963647379581945\n",
            "[41, 61, 49, 51, 36, 53]\n",
            "[41, 61, 49, 36, 53]\n",
            "Finished 3400 examples\n",
            "Source: rajman\n",
            "Original: राजमां\n",
            "Predicted: राजमान\n",
            "\n",
            "Accuracy: 0.200235224933843\n",
            "[43, 51, 24, 41, 51, 3]\n",
            "[43, 51, 24, 41, 51, 36]\n",
            "Finished 3500 examples\n",
            "Source: reshey\n",
            "Original: रेशे\n",
            "Predicted: रेशे\n",
            "\n",
            "Accuracy: 0.20108540417023707\n",
            "[43, 58, 46, 58]\n",
            "[43, 58, 46, 58]\n",
            "Finished 3600 examples\n",
            "Source: lanchar\n",
            "Original: लांचर\n",
            "Predicted: लांचर\n",
            "\n",
            "Accuracy: 0.20216606498194944\n",
            "[44, 51, 3, 22, 43]\n",
            "[44, 51, 3, 22, 43]\n",
            "Finished 3700 examples\n",
            "Source: varnit\n",
            "Original: वर्णित\n",
            "Predicted: वर्णित\n",
            "\n",
            "Accuracy: 0.20102674952715482\n",
            "[45, 43, 63, 31, 52, 32]\n",
            "[45, 43, 63, 31, 52, 32]\n",
            "Finished 3800 examples\n",
            "Source: vimarshon\n",
            "Original: विमर्शों\n",
            "Predicted: विमार्षों\n",
            "\n",
            "Accuracy: 0.20257826887661143\n",
            "[45, 52, 41, 43, 63, 46, 61, 3]\n",
            "[45, 52, 41, 51, 43, 63, 47, 61, 3]\n",
            "Finished 3900 examples\n",
            "Source: shamitabh\n",
            "Original: शमिताभ\n",
            "Predicted: शामितभभ\n",
            "\n",
            "Accuracy: 0.2025121763650346\n",
            "[46, 41, 52, 32, 51, 40]\n",
            "[46, 51, 41, 52, 32, 40, 40]\n",
            "Finished 4000 examples\n",
            "Source: samprbhuta\n",
            "Original: संप्रभुता\n",
            "Predicted: संपर्भूता\n",
            "\n",
            "Accuracy: 0.20469882529367658\n",
            "[48, 3, 37, 63, 43, 40, 54, 32, 51]\n",
            "[48, 3, 37, 43, 63, 40, 55, 32, 51]\n",
            "Finished 4100 examples\n",
            "Source: sargana\n",
            "Original: सरगना\n",
            "Predicted: सर्गना\n",
            "\n",
            "Accuracy: 0.20580346257010484\n",
            "[48, 43, 19, 36, 51]\n",
            "[48, 43, 63, 19, 36, 51]\n",
            "Finished 4200 examples\n",
            "Source: simate\n",
            "Original: सिमटे\n",
            "Predicted: सिमाते\n",
            "\n",
            "Accuracy: 0.20328493215900975\n",
            "[48, 52, 41, 27, 58]\n",
            "[48, 52, 41, 51, 32, 58]\n",
            "Finished 4300 examples\n",
            "Source: self\n",
            "Original: सेल्फ\n",
            "Predicted: सेल\n",
            "\n",
            "Accuracy: 0.20390606835619624\n",
            "[48, 58, 44, 63, 38]\n",
            "[48, 58, 44]\n",
            "Finished 4400 examples\n",
            "Source: sweet\n",
            "Original: स्वीट\n",
            "Predicted: स्वीत\n",
            "\n",
            "Accuracy: 0.20472619859122926\n",
            "[48, 63, 45, 53, 27]\n",
            "[48, 63, 45, 53, 32]\n",
            "Finished 4500 examples\n",
            "Source: hostes\n",
            "Original: होस्टेस\n",
            "Predicted: हस्तेस\n",
            "\n",
            "Accuracy: 0.2043990224394579\n",
            "[49, 61, 48, 63, 27, 58, 48]\n",
            "[49, 48, 63, 32, 58, 48]\n",
            "Test Accuracy: 921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy of attention model\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mk656PgIUMv",
        "outputId": "b762f95d-feeb-4c8d-d8b1-67afbe2bbf37"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20457574411372723"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict2 = [{\"input\":lang[i], \"true\": org[i], \"predicted\": pred[i]} for i in range(len(lang))] \n",
        "test_predictions = pd.DataFrame(dict2)\n",
        "test_predictions.to_csv('predictions_attention.csv', index=False, sep='\\t')"
      ],
      "metadata": {
        "id": "GHOW3q0cB8wc"
      },
      "execution_count": 44,
      "outputs": []
    }
  ]
}